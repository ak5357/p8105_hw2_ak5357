Data Science Homework 2
================
ak5357
2024-09-26

# Problem 1

### *NYC Transit Data*

**Loading and cleaning the data, keeping only the following variables:**

- Line
- Station Name
- Station Latitude and Longitude
- Routes Served
- Entry
- Vending
- Entrance Type
- ADA Compliance

``` r
transit_df = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", #load data
           na = c("NA", " ", "")) |> #define possible NA values
  janitor::clean_names() |> #standardize column names
  select(line, starts_with("station"), -station_location, #select focus columns
         starts_with("route"), entry, vending, entrance_type, ada) |> 
  mutate(
    entry = case_match( #convert entry column from char to lgl
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE,
    )) |> 
  mutate( #ensure all route columns are char type for consistency
    across(
      starts_with("route"), as.character
    ))
```

The dataset contains information related to each entrance and exit for
each subway station in New York City.

(Dear Reader: After much consideration, I have come to a difficult
decision… Since this question doesn’t count for points, I will forego
further explanation about the dataset’s variables. My sincere apologies.
*tips hat*)

The data are not tidy, since there is significant redundance among the
columns, specifically those related to the routes.

**Answering questions with data.**

``` r
num_distinct_stations = transit_df |> 
  distinct(line, station_name) |> 
  nrow()

num_ada_stations = transit_df |> 
  filter(ada == TRUE) |> 
  nrow()

p_no_vending_yes_entry = transit_df |> 
  summarize(
    proportion = mean(vending == "NO" & entry == TRUE)
    ) |> 
  round(4)
```

Here are some interesting facts about the data:

- The dataset contains information about **465** distinct stations.
- Of the 1868 entrances and exists documented in the dataset, only
  **468** are ADA compliant.
- The proportion of station entrances / exits without vending that allow
  entrance is **0.0369**, or **3.69**%.

**Reformatting data so that route number and route name are distinct
variables.**

``` r
transit_dr_by_route = transit_df |> 
  pivot_longer(
    cols = starts_with("route"),
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = "route"
  ) |> 
  filter(!is.na(route_name))
```

**Answering more questions with data.**

``` r
n_distinct_A_stations = transit_dr_by_route |> 
  filter(route_name == "A")  |> 
  distinct(line, station_name) |> 
  nrow()

n_ada_A_stations = transit_dr_by_route |> 
  filter(route_name == "A" & ada == TRUE) |> 
  distinct(line, station_name) |> 
  nrow()
```

Here are some more interesting facts about the data:

- There are **60** distinct stations that serve the A train.
- Of the stations that serve the A train, only **17** are ADA compliant.

# Problem 2

### *Mr. Trash Wheel*

**Loading and cleaning the data.**

Writing a function below to read an excel sheet into a dataframe, given
the parameters `filepath` and `sheet_name`. The default for the
`sheet_name` parameter is `NULL`, in case I want to use the function on
an excel with only one sheet.

I decided to use a function to read in the trash wheels’ data to
minimize errors by avoiding redundant code and to standardize the
loading/cleaning process across all trash wheels’ excel sheets.

``` r
sheet_to_df = function(filepath, sheet_name=NULL){
  output = read_excel(
                    path = filepath,
                    sheet = sheet_name,
                    na = c("NA", " ", ""),
                    skip = 1,
                    trim_ws = TRUE
                    ) |> 
    janitor::clean_names() |> #clean column names
    select(where(~ any(!is.na(.)))) #remove any columns with only NA values
  
  return(output)
}
```

I’m choosing to handle the alteration, removal, and addition of specific
columns outside of the `sheet_to_df` function to keep the function as
minimal and generalizable as possible.

``` r
# Assigning trash wheel excel filepath to variable, since it will be used repeatedly
trash_excel_filepath = "data/202309 Trash Wheel Collection Data.xlsx"

# Mr. Trash Wheel
mr_trash_df = sheet_to_df(trash_excel_filepath, "Mr. Trash Wheel") |>
  select(-homes_powered) |> #remove non-dumpster-related columns
  mutate(
    sports_balls = as.integer(sports_balls), #round sports balls column
    year = as.numeric(year), #ensure the year data type is dbl
    wheel_name = "Mr. Trash Wheel" #add name column
    )

# Professor Trash Wheel
professor_trash_df = sheet_to_df(trash_excel_filepath, "Professor Trash Wheel") |>
  select(-homes_powered) |> #remove non-dumpster-related columns
  mutate(
    wheel_name = "Professor Trash Wheel" #add name column
  )

# Gwynnda Trash Wheel
gwynnda_trash_df = sheet_to_df(trash_excel_filepath, "Gwynnda Trash Wheel") |>
  select(-homes_powered) |> #remove non-dumpster-related columns
  mutate(
    wheel_name = "Gwynnda Trash Wheel" #add name column
  )
```

**Combining the Trash Wheel dataframes.**

``` r
trash_wheels_df = 
  bind_rows(mr_trash_df, professor_trash_df, gwynnda_trash_df) |> 
  relocate(wheel_name)
```

**Answering questions with data.**

``` r
# Number of total observations
n_total_observations = nrow(trash_wheels_df)

# Number of observations from each wheel
n_mr_trash_observations = trash_wheels_df |> 
  filter(wheel_name == "Mr. Trash Wheel") |> 
  nrow()

n_professor_observations = trash_wheels_df |> 
  filter(wheel_name == "Professor Trash Wheel") |> 
  nrow()

n_gwynnda_observations = trash_wheels_df |> 
  filter(wheel_name == "Gwynnda Trash Wheel") |> 
  nrow()

#

trash_wheels_df |> colnames()
```

    ##  [1] "wheel_name"         "dumpster"           "month"             
    ##  [4] "year"               "date"               "weight_tons"       
    ##  [7] "volume_cubic_yards" "plastic_bottles"    "polystyrene"       
    ## [10] "cigarette_butts"    "glass_bottles"      "plastic_bags"      
    ## [13] "wrappers"           "sports_balls"

``` r
mr_trash_df |>  colnames()
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "plastic_bags"       "wrappers"          
    ## [13] "sports_balls"       "wheel_name"

``` r
gwynnda_trash_df |> colnames()
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "plastic_bags"       "wrappers"           "wheel_name"

``` r
professor_trash_df |> colnames()
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "plastic_bags"       "wrappers"          
    ## [13] "wheel_name"

``` r
trash_wheels_df |> 
  group_by(wheel_name) |> 
  summarise(
    sum_vol = sum(volume_cubic_yards, na.rm = TRUE),
    sum_weight = sum(weight_tons, na.rm = TRUE),
    max_vol = max(volume_cubic_yards, na.rm = TRUE),
    max_weight = max(weight_tons, na.rm = TRUE)
  )
```

    ## # A tibble: 3 × 5
    ##   wheel_name            sum_vol sum_weight max_vol max_weight
    ##   <chr>                   <dbl>      <dbl>   <dbl>      <dbl>
    ## 1 Gwynnda Trash Wheel      4618       903.    2309       452.
    ## 2 Mr. Trash Wheel         17868      3750.    8934      1875.
    ## 3 Professor Trash Wheel    3092       433.    1546       216.

The resulting dataset contains **849** observations–
