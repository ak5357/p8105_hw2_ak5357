---
title: "Data Science Homework 2"
author: "ak5357"
date: "2024-09-26"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
```

# Problem 1
### _NYC Transit Data_

**Loading and cleaning the data, keeping only the following variables:**

* Line
* Station Name
* Station Latitude and Longitude
* Routes Served
* Entry
* Vending
* Entrance Type
* ADA Compliance

```{r import_subway_data, message = FALSE}
transit_df = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", #load data
           na = c("NA", " ", "")) |> #define possible NA values
  janitor::clean_names() |> #standardize column names
  select(line, starts_with("station"), -station_location, #select focus columns
         starts_with("route"), entry, vending, entrance_type, ada) |> 
  mutate(
    entry = case_match( #convert entry column from char to lgl
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE,
    )) |> 
  mutate( #ensure all route columns are char type for consistency
    across(
      starts_with("route"), as.character
    ))
```

The dataset contains information related to each entrance and exit for each subway station in New York City.

(Dear Reader: After much consideration, I have come to a difficult decision... Since this question doesn't count for points, I will forego further explanation about the dataset's variables. My sincere apologies. _tips hat_)

The data are not tidy, since there is significant redundance among the columns, specifically those related to the routes.


**Answering questions with data.**
```{r data_questions}
num_distinct_stations = transit_df |> 
  distinct(line, station_name) |> 
  nrow()

num_ada_stations = transit_df |> 
  filter(ada == TRUE) |> 
  nrow()

p_no_vending_yes_entry = transit_df |> 
  summarize(
    proportion = mean(vending == "NO" & entry == TRUE)
    ) |> 
  round(4)
```

Here are some interesting facts about the data:

* The dataset contains information about **`r num_distinct_stations`** distinct stations.
* Of the `r nrow(transit_df)` entrances and exists documented in the dataset, only **`r num_ada_stations`** are ADA compliant.
* The proportion of station entrances / exits without vending that allow entrance is **`r p_no_vending_yes_entry`**, or **`r p_no_vending_yes_entry * 100`**%.

**Reformatting data so that route number and route name are distinct variables.**
```{r reformat_df_by_route}
transit_dr_by_route = transit_df |> 
  pivot_longer(
    cols = starts_with("route"),
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = "route"
  ) |> 
  filter(!is.na(route_name))
```


**Answering more questions with data.**
```{r _distinct_A_stations}
n_distinct_A_stations = transit_dr_by_route |> 
  filter(route_name == "A")  |> 
  distinct(line, station_name) |> 
  nrow()

n_ada_A_stations = transit_dr_by_route |> 
  filter(route_name == "A" & ada == TRUE) |> 
  distinct(line, station_name) |> 
  nrow()
```

Here are some more interesting facts about the data:

* There are **`r n_distinct_A_stations`** distinct stations that serve the A train.
* Of the stations that serve the A train, only **`r n_ada_A_stations`** are ADA compliant.


# Problem 2
### _Mr. Trash Wheel_

**Loading and cleaning the data.**

Writing a function below to read an excel sheet into a dataframe, given the parameters `filepath` and `sheet_name`. The default for the `sheet_name` parameter is `NULL`, in case I want to use the function on an excel with only one sheet. 

I decided to use a function to read in the trash wheels' data to minimize errors by avoiding redundant code and to standardize the loading/cleaning process across all trash wheels' excel sheets.

```{r read_excel_sheet_function}
sheet_to_df = function(filepath, sheet_name=NULL){
  output = read_excel(
                    path = filepath,
                    sheet = sheet_name,
                    na = c("NA", " ", ""),
                    skip = 1,
                    trim_ws = TRUE
                    ) |> 
    janitor::clean_names() |> #clean column names
    select(where(~ any(!is.na(.)))) #remove any columns with only NA values
  
  return(output)
}
```


I'm choosing to handle the alteration, removal, and addition of specific columns outside of the `sheet_to_df` function to keep the function as minimal and generalizable as possible.

```{r load_trash_wheels_data, message = FALSE}
# Assigning trash wheel excel filepath to variable, since it will be used repeatedly
trash_excel_filepath = "data/202309 Trash Wheel Collection Data.xlsx"

# Mr. Trash Wheel
mr_trash_df = sheet_to_df(trash_excel_filepath, "Mr. Trash Wheel") |>
  select(-homes_powered) |> #remove non-dumpster-related columns
  mutate(
    sports_balls = as.integer(sports_balls), #round sports balls column
    year = as.numeric(year), #ensure the year data type is dbl
    wheel_name = "Mr. Trash Wheel" #add name column
    )

# Professor Trash Wheel
professor_trash_df = sheet_to_df(trash_excel_filepath, "Professor Trash Wheel") |>
  select(-homes_powered) |> #remove non-dumpster-related columns
  mutate(
    wheel_name = "Professor Trash Wheel" #add name column
  )

# Gwynnda Trash Wheel
gwynnda_trash_df = sheet_to_df(trash_excel_filepath, "Gwynnda Trash Wheel") |>
  select(-homes_powered) |> #remove non-dumpster-related columns
  mutate(
    wheel_name = "Gwynnda Trash Wheel" #add name column
  )

```


**Combining the Trash Wheel dataframes.**
```{r combine_trash_dfs}
trash_wheels_df = 
  bind_rows(mr_trash_df, professor_trash_df, gwynnda_trash_df) |> 
  relocate(wheel_name)
```


**Answering questions with data.**
```{r}
# Number of total observations
n_total_observations = nrow(trash_wheels_df)

# Number of observations from each wheel
n_mr_trash_observations = trash_wheels_df |> 
  filter(wheel_name == "Mr. Trash Wheel") |> 
  nrow()

n_professor_observations = trash_wheels_df |> 
  filter(wheel_name == "Professor Trash Wheel") |> 
  nrow()

n_gwynnda_observations = trash_wheels_df |> 
  filter(wheel_name == "Gwynnda Trash Wheel") |> 
  nrow()

#

trash_wheels_df |> colnames()

mr_trash_df |>  colnames()
gwynnda_trash_df |> colnames()
professor_trash_df |> colnames()

trash_wheels_df |> 
  group_by(wheel_name) |> 
  summarise(
    sum_vol = sum(volume_cubic_yards, na.rm = TRUE),
    sum_weight = sum(weight_tons, na.rm = TRUE),
    max_vol = max(volume_cubic_yards, na.rm = TRUE),
    max_weight = max(weight_tons, na.rm = TRUE)
  )


```



The resulting dataset contains **`r nrow(trash_wheels_df)`** observations--





